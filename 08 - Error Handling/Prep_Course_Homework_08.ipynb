{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para importar un modulo que no esta en la misma carpeta en la que estoy trabajando\n",
    "# Con append decimos que a nuestro espacio de trabajo se agrega esa carpeta x\n",
    "\n",
    "import sys\n",
    "sys.path.append (r'/C:/Users/peros/OneDrive/Documentos/Henry/Python-Prep/08 - Error Handling/herramientas_mio.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesario para hacer \"importlib.reload(h)\"\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo el archivo herramientas mio y digo que se llamara h\n",
    "import herramientas_mio as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_mio' from 'c:\\\\Users\\\\peros\\\\OneDrive\\\\Documentos\\\\Henry\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas_mio.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si hago una modificacion en el archivo principal \"herramientas_mio.py\" para que me tome los cambios\n",
    "#cuando lo vuelva a importar, debo hacer esto antes de importarlo:\n",
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llamo a la clase Herramientas dentro del archivo herramientas mio, y le ingreso un valor\n",
    "h1 = h.Herramientas([4,2,5])\n",
    "#[4,2,5,6,4,4,4,7,11,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uso la funcion valor modal que esta en la clase Herramientas \n",
    "h1.valor_modal(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llamo a la clase Herramientas dentro del archivo herramientas mio, y le ingreso un valor\n",
    "h1 = h.Herramientas([4,2,5,6,4,4,4,7,11,7,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los valores esperados son: ['celsius', 'farenheit', 'kelvin']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrege a mi clse Herramientas un mensaje de alerta para cuando se ingresan mal\n",
    "# los parametros de la funcion \"conversion_grados\"\n",
    "h1.conversion_grados(\"celsiu\",\"farenheit\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"unittest.TestCase\" me permite hacer diferentes funciones\n",
    "# cada funcion es un caso de prueba diferente\n",
    "\n",
    "class ver_errores(unittest.TestCase):\n",
    "\n",
    "    # assertRaises es un test para ver que pasa cuando intancio la clase Herramientas \n",
    "    # con un parametro especifico\n",
    "    def test_creacion_1 (self):\n",
    "        parametro = \"hola\"\n",
    "        self.assertRaises(ValueError,h.Herramientas,parametro)\n",
    "\n",
    "    # assertEqual es otro test\n",
    "    # comparo el resultado obtenido con el valor esperado\n",
    "    def test_creacion_2 (self):\n",
    "        parametro = [2,4,6,7]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        self.assertEqual(h1.lista,parametro)\n",
    "\n",
    "    # este es el que mas entiendo\n",
    "    def test_valor_modal_1 (self):\n",
    "        parametro = [3,5,5,4,5,3,3]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        resultado =[moda,veces]\n",
    "        resultado_esperado = [5,3]\n",
    "        self.assertEqual(resultado,resultado_esperado)\n",
    "\n",
    "    def test_valor_modal_2 (self):\n",
    "        parametro = [3,5,5,4,5,3,3]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        moda, veces = h1.valor_modal(True)\n",
    "        resultado =[moda,veces]\n",
    "        resultado_esperado = [3,3]\n",
    "        self.assertEqual(resultado,resultado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_creacion_1 (__main__.ver_errores) ... ok\n",
      "test_creacion_2 (__main__.ver_errores) ... ok\n",
      "test_valor_modal_1 (__main__.ver_errores) ... ok\n",
      "test_valor_modal_2 (__main__.ver_errores) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f3aa4aeb60>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con esto veo el resltado de mi test\n",
    "# \"exit=False\" me sirve para que aunque una prueba de mal, siga con las otras\n",
    "# si da FAIL es que el resultado no es el esperado\n",
    "# si da ERROR es que no se pudo ejecutar bien \n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_mio' from 'c:\\\\Users\\\\peros\\\\OneDrive\\\\Documentos\\\\Henry\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas_mio.py'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([4,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['False', 'True', 'True']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.verifica_primo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ver_errores(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primo (self):\n",
    "        parametro = [4,2,5]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        resultado = h1.verifica_primo()\n",
    "        resultado_esperado = ['False', 'True', 'True']\n",
    "        self.assertEqual(resultado,resultado_esperado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_verifica_primo (__main__.ver_errores) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f3aa4acca0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_mio' from 'c:\\\\Users\\\\peros\\\\OneDrive\\\\Documentos\\\\Henry\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas_mio.py'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([4,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[277.15, 275.15, 278.15]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius','kelvin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ver_errores(unittest.TestCase):\n",
    "\n",
    "    def test_conversion_grados (self):\n",
    "        parametro = [4,2,5]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        resultado = h1.conversion_grados('celsius','kelvin')\n",
    "        resultado_esperado = [277.15, 275.15, 278.15]\n",
    "        self.assertEqual(resultado,resultado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_conversion_grados (__main__.ver_errores) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f3ab5ab940>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_mio' from 'c:\\\\Users\\\\peros\\\\OneDrive\\\\Documentos\\\\Henry\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas_mio.py'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([4,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 2, 120]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ver_errores(unittest.TestCase):\n",
    "\n",
    "    def test_factorial (self):\n",
    "        parametro = [4,2,5]\n",
    "        h1 = h.Herramientas(parametro)\n",
    "        resultado = h1.factorial()\n",
    "        resultado_esperado = [24,2,120]\n",
    "        self.assertEqual(resultado,resultado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_factorial (__main__.ver_errores) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f3aa50c4f0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
